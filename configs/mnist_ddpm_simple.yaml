# MNIST configuration for Simple DDPM baseline (Ho et al. 2020)
# Uses linear beta schedule (original DDPM)
# Same architecture as Bridge for fair comparison

name: ddpm_mnist_simple
output_dir: ./outputs/ddpm_mnist_simple
method: ddpm
mlflow_tracking_uri: sqlite:///./outputs/mlflow.db

model:
  in_channels: 1
  out_channels: 1
  sample_size: 28
  block_out_channels: [64, 64, 64]
  layers_per_block: 2
  down_block_types:
    - DownBlock2D
    - AttnDownBlock2D
    - AttnDownBlock2D
  up_block_types:
    - AttnUpBlock2D
    - AttnUpBlock2D
    - UpBlock2D
  attention_head_dim: 4
  dropout: 0.0

training:
  batch_size: 128
  num_steps: 40000
  learning_rate: 0.0001
  weight_decay: 0.0
  grad_clip_norm: 1.0
  checkpoint_every: 5000
  log_every: 100
  seed: 42

ddpm:
  num_train_timesteps: 1000
  beta_schedule: linear

sampling:
  num_steps: 1000
  num_samples: 64
  show_progress: true
  clip_samples: true

data:
  dataset: mnist
  data_dir: ./data
  image_size: 28
  num_workers: 4
  pin_memory: true
